{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f74a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from pnpl.datasets import LibriBrainPhoneme, LibriBrainCompetitionHoldout\n",
    "\n",
    "from libribrain_experiments.grouped_dataset import MyGroupedDatasetV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad742c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dogeon/libribrain_phoneme/.venv/lib/python3.12/site-packages/pnpl/datasets/libribrain2025/competition_holdout_dataset.py:156: UserWarning: Standardization parameters are ignored for phoneme holdout; data is assumed pre-standardized. Setting standardize=False.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_train_dataset = LibriBrainPhoneme(\n",
    "    data_path=\"./data/\",\n",
    "    tmin=0.0,\n",
    "    tmax=0.5,\n",
    "    standardize=True,\n",
    "    partition=\"train\",\n",
    ")\n",
    "\n",
    "train_dataset = MyGroupedDatasetV3(\n",
    "    _train_dataset,\n",
    "    grouped_samples=100,\n",
    "    drop_remaining=False,\n",
    "    average_grouped_samples=True,\n",
    "    state_cache_path=Path(\"./data_preprocessed/groupedv3/train_grouped_100.pt\"),\n",
    "    shuffle=True,\n",
    "    # augment=True,  # Set to True if you want to apply data augmentation\n",
    ")\n",
    "\n",
    "_val_dataset = LibriBrainPhoneme(\n",
    "    data_path=\"./data/\",\n",
    "    tmin=0.0,\n",
    "    tmax=0.5,\n",
    "    standardize=True,\n",
    "    partition=\"validation\",\n",
    ")\n",
    "\n",
    "val_dataset = MyGroupedDatasetV3(\n",
    "    _val_dataset,\n",
    "    grouped_samples=100,\n",
    "    drop_remaining=False,\n",
    "    average_grouped_samples=True,\n",
    "    state_cache_path=Path(\"./data_preprocessed/groupedv3/val_grouped_100.pt\"),\n",
    "    shuffle=True,\n",
    "    # augment=True,  # Set to True if you want to apply data augmentation\n",
    ")\n",
    "holdout_dataset = LibriBrainCompetitionHoldout(\n",
    "    data_path=\"./data/\",\n",
    "    task=\"phoneme\",\n",
    "    tmin=0.0,\n",
    "    tmax=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e50d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shape(dataset, holdout=False):\n",
    "    # dataset[0].shape == (306, 125)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=256,\n",
    "        num_workers=4,\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    all_sum = torch.zeros((1, 306)).to(device)\n",
    "    all_sum_square = torch.zeros((1, 306)).to(device)\n",
    "    count = torch.tensor(len(dataset), dtype=torch.float64)\n",
    "\n",
    "    for batch in tqdm(loader):\n",
    "        batch: np.ndarray = batch.to(\n",
    "            device) if holdout else batch[0].to(device)\n",
    "        all_sum += batch.sum(axis=(0, 2))\n",
    "        all_sum_square += ((batch / torch.sqrt(count)) ** 2).sum(axis=(0, 2))\n",
    "        count += batch.shape[0]\n",
    "\n",
    "    mean = all_sum / count\n",
    "    std = torch.sqrt(all_sum_square - mean ** 2)\n",
    "    \n",
    "    print(\"  Mean of Mean:\", mean[~mean.isnan()].mean().item())\n",
    "    print(\"  Std of Mean:\", mean[~mean.isnan()].std().item())\n",
    "    print(\"  Mean of Std:\", std[~std.isnan()].mean().item())\n",
    "    print(\"  Std of Std:\", std[~std.isnan()].std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e95de8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean of Mean: -0.17622576653957367\n",
      "  Std of Mean: 2.6009180545806885\n",
      "  Mean of Std: 5.760135173797607\n",
      "  Std of Std: 2.3829505443573\n"
     ]
    }
   ],
   "source": [
    "print(\"Holdout:\")\n",
    "print_shape(holdout_dataset, holdout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd8d37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5222/5222 [02:44<00:00, 31.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean of Mean: -0.0296162161976099\n",
      "  Std of Mean: 0.28274792432785034\n",
      "  Mean of Std: 2.2516109943389893\n",
      "  Std of Std: 0.6436986327171326\n",
      "Train (Grouped):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [02:03<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean of Mean: -0.029526973143219948\n",
      "  Std of Mean: 0.2823629379272461\n",
      "  Mean of Std: 0.1705937534570694\n",
      "  Std of Std: 0.0689060166478157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\")\n",
    "print_shape(_train_dataset)\n",
    "\n",
    "print(\"Train (Grouped):\")\n",
    "print_shape(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6dcc7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1109/1109 [00:32<00:00, 34.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean of Mean: 0.07536603510379791\n",
      "  Std of Mean: 1.0090750455856323\n",
      "  Mean of Std: 4.097787857055664\n",
      "  Std of Std: 1.6319663524627686\n",
      "Val (Grouped):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:45<00:00,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean of Mean: 0.07475172728300095\n",
      "  Std of Mean: 1.0109822750091553\n",
      "  Mean of Std: 0.39236754179000854\n",
      "  Std of Std: 0.17127688229084015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Val:\")\n",
    "print_shape(_val_dataset)\n",
    "\n",
    "print(\"Val (Grouped):\")\n",
    "print_shape(val_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libribrain-phoneme (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
