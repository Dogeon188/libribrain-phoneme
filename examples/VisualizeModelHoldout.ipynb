{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e68f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"out/phoneme-baseline-l/best-val_bal_acc-baseline-l-hpo-1-epoch=09-val_f1_macro=0.5365.ckpt\"\n",
    "# checkpoint_path = \"out/phoneme-resnet/best-val_bal_acc-resnet-hpo-1-epoch=09-val_f1_macro=0.5457.ckpt\"\n",
    "# checkpoint_path = \"out/phoneme-baseline-xl/best-val_bal_acc-baseline-xl-hpo-1-epoch=09-val_f1_macro=0.4305.ckpt\"\n",
    "checkpoint_path = \"out/phoneme-megt/best-val_bal_acc-megt-s-hpo-0-epoch=09-val_f1_macro=0.6605.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a6c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from libribrain_experiments.models.configurable_modules.classification_module import ClassificationModule\n",
    "from pnpl.datasets.libribrain2025 import constants_utils\n",
    "\n",
    "constants_utils.set_remote_constants_url(\n",
    "    f\"{(Path(os.getcwd()) / 'constants.json').as_uri()}\")\n",
    "constants_utils.refresh_constants()\n",
    "model = ClassificationModule.load_from_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe4c519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   | Name                                       | Type                            | Params | Mode \n",
       "--------------------------------------------------------------------------------------------------------\n",
       "0  | modules_list                               | ModuleList                      | 6.1 M  | train\n",
       "1  | modules_list.0                             | Conv1d                          | 548 K  | train\n",
       "2  | modules_list.1                             | ResnetBlock                     | 262 K  | train\n",
       "3  | modules_list.1.module_list                 | ModuleList                      | 262 K  | train\n",
       "4  | modules_list.1.module_list.0               | ELU                             | 0      | train\n",
       "5  | modules_list.1.module_list.1               | Conv1d                          | 196 K  | train\n",
       "6  | modules_list.1.module_list.2               | ELU                             | 0      | train\n",
       "7  | modules_list.1.module_list.3               | Conv1d                          | 65.8 K | train\n",
       "8  | modules_list.2                             | ELU                             | 0      | train\n",
       "9  | modules_list.3                             | Permute                         | 0      | train\n",
       "10 | modules_list.4                             | PositionalEncoding              | 0      | train\n",
       "11 | modules_list.4.dropout                     | Dropout                         | 0      | train\n",
       "12 | modules_list.5                             | TransformerEncoder              | 5.3 M  | train\n",
       "13 | modules_list.5.layers                      | ModuleList                      | 5.3 M  | train\n",
       "14 | modules_list.5.layers.0                    | TransformerEncoderLayer         | 1.3 M  | train\n",
       "15 | modules_list.5.layers.0.self_attn          | MultiheadAttention              | 263 K  | train\n",
       "16 | modules_list.5.layers.0.self_attn.out_proj | NonDynamicallyQuantizableLinear | 65.8 K | train\n",
       "17 | modules_list.5.layers.0.linear1            | Linear                          | 526 K  | train\n",
       "18 | modules_list.5.layers.0.dropout            | Dropout                         | 0      | train\n",
       "19 | modules_list.5.layers.0.linear2            | Linear                          | 524 K  | train\n",
       "20 | modules_list.5.layers.0.norm1              | LayerNorm                       | 512    | train\n",
       "21 | modules_list.5.layers.0.norm2              | LayerNorm                       | 512    | train\n",
       "22 | modules_list.5.layers.0.dropout1           | Dropout                         | 0      | train\n",
       "23 | modules_list.5.layers.0.dropout2           | Dropout                         | 0      | train\n",
       "24 | modules_list.5.layers.1                    | TransformerEncoderLayer         | 1.3 M  | train\n",
       "25 | modules_list.5.layers.1.self_attn          | MultiheadAttention              | 263 K  | train\n",
       "26 | modules_list.5.layers.1.self_attn.out_proj | NonDynamicallyQuantizableLinear | 65.8 K | train\n",
       "27 | modules_list.5.layers.1.linear1            | Linear                          | 526 K  | train\n",
       "28 | modules_list.5.layers.1.dropout            | Dropout                         | 0      | train\n",
       "29 | modules_list.5.layers.1.linear2            | Linear                          | 524 K  | train\n",
       "30 | modules_list.5.layers.1.norm1              | LayerNorm                       | 512    | train\n",
       "31 | modules_list.5.layers.1.norm2              | LayerNorm                       | 512    | train\n",
       "32 | modules_list.5.layers.1.dropout1           | Dropout                         | 0      | train\n",
       "33 | modules_list.5.layers.1.dropout2           | Dropout                         | 0      | train\n",
       "34 | modules_list.5.layers.2                    | TransformerEncoderLayer         | 1.3 M  | train\n",
       "35 | modules_list.5.layers.2.self_attn          | MultiheadAttention              | 263 K  | train\n",
       "36 | modules_list.5.layers.2.self_attn.out_proj | NonDynamicallyQuantizableLinear | 65.8 K | train\n",
       "37 | modules_list.5.layers.2.linear1            | Linear                          | 526 K  | train\n",
       "38 | modules_list.5.layers.2.dropout            | Dropout                         | 0      | train\n",
       "39 | modules_list.5.layers.2.linear2            | Linear                          | 524 K  | train\n",
       "40 | modules_list.5.layers.2.norm1              | LayerNorm                       | 512    | train\n",
       "41 | modules_list.5.layers.2.norm2              | LayerNorm                       | 512    | train\n",
       "42 | modules_list.5.layers.2.dropout1           | Dropout                         | 0      | train\n",
       "43 | modules_list.5.layers.2.dropout2           | Dropout                         | 0      | train\n",
       "44 | modules_list.5.layers.3                    | TransformerEncoderLayer         | 1.3 M  | train\n",
       "45 | modules_list.5.layers.3.self_attn          | MultiheadAttention              | 263 K  | train\n",
       "46 | modules_list.5.layers.3.self_attn.out_proj | NonDynamicallyQuantizableLinear | 65.8 K | train\n",
       "47 | modules_list.5.layers.3.linear1            | Linear                          | 526 K  | train\n",
       "48 | modules_list.5.layers.3.dropout            | Dropout                         | 0      | train\n",
       "49 | modules_list.5.layers.3.linear2            | Linear                          | 524 K  | train\n",
       "50 | modules_list.5.layers.3.norm1              | LayerNorm                       | 512    | train\n",
       "51 | modules_list.5.layers.3.norm2              | LayerNorm                       | 512    | train\n",
       "52 | modules_list.5.layers.3.dropout1           | Dropout                         | 0      | train\n",
       "53 | modules_list.5.layers.3.dropout2           | Dropout                         | 0      | train\n",
       "54 | modules_list.6                             | Linear                          | 10.0 K | train\n",
       "55 | modules_list.7                             | ELU                             | 0      | train\n",
       "56 | modules_list.8                             | AvgPool2d                       | 0      | train\n",
       "57 | modules_list.9                             | Flatten                         | 0      | train\n",
       "58 | loss_fn                                    | CrossEntropyLoss                | 0      | train\n",
       "59 | accuracy                                   | MulticlassAccuracy              | 0      | train\n",
       "60 | balanced_accuracy                          | MulticlassAccuracy              | 0      | train\n",
       "61 | f1_micro                                   | MulticlassF1Score               | 0      | train\n",
       "62 | f1_macro                                   | MulticlassF1Score               | 0      | train\n",
       "63 | precision_micro                            | MulticlassPrecision             | 0      | train\n",
       "64 | precision_macro                            | MulticlassPrecision             | 0      | train\n",
       "65 | binary_accuracy                            | BinaryAccuracy                  | 0      | train\n",
       "66 | binary_precision                           | BinaryPrecision                 | 0      | train\n",
       "67 | binary_recall                              | BinaryRecall                    | 0      | train\n",
       "68 | binary_f1                                  | BinaryF1Score                   | 0      | train\n",
       "--------------------------------------------------------------------------------------------------------\n",
       "6.1 M     Trainable params\n",
       "0         Non-trainable params\n",
       "6.1 M     Total params\n",
       "24.326    Total estimated model params size (MB)\n",
       "69        Modules in train mode\n",
       "0         Modules in eval mode"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "\n",
    "ModelSummary(model, max_depth=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89373031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dogeon/libribrain/phoneme/.venv/lib/python3.12/site-packages/pnpl/datasets/libribrain2025/competition_holdout_dataset.py:156: UserWarning: Standardization parameters are ignored for phoneme holdout; data is assumed pre-standardized. Setting standardize=False.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pnpl.datasets import LibriBrainCompetitionHoldout\n",
    "\n",
    "\n",
    "visualization_dataset =  LibriBrainCompetitionHoldout(\n",
    "    data_path=\"./data/\",\n",
    "    task=\"phoneme\",\n",
    "    tmin=0.0,\n",
    "    tmax=0.5,\n",
    "    standardize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac3a566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d738d078a9a48a08575d2ea34501262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(ToggleButtons(description='Layer:', index=9, options=('layer_0', 'layer_1', 'lay…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dogeon/libribrain/phoneme/.venv/lib/python3.12/site-packages/jupyter_client/session.py:721: UserWarning:\n",
      "\n",
      "Message serialization failed with:\n",
      "Out of range float values are not JSON compliant: nan\n",
      "Supporting this message is deprecated in jupyter-client 7, please make sure your message is JSON-compliant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# Sample & collect activations\n",
    "\n",
    "activations = {}\n",
    "\n",
    "sample_id = np.random.randint(0, len(visualization_dataset))\n",
    "sample = visualization_dataset[sample_id].unsqueeze(0)\n",
    "sample = sample / 4.0\n",
    "\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach().cpu()\n",
    "    return hook\n",
    "\n",
    "\n",
    "# Register hooks for each layer in modules_list\n",
    "for idx, layer in enumerate(model.modules_list):\n",
    "    layer.register_forward_hook(get_activation(f'layer_{idx}'))\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    _ = model.forward(sample.to(model.device))\n",
    "\n",
    "\n",
    "activations_per_row = 32\n",
    "\n",
    "# Register hooks for each layer in modules_list\n",
    "for idx, layer in enumerate(model.modules_list):\n",
    "    layer.register_forward_hook(get_activation(f'layer_{idx}'))\n",
    "\n",
    "plot_fig: go.FigureWidget = go.FigureWidget()\n",
    "plot_fig_input: go.FigureWidget = go.FigureWidget()\n",
    "\n",
    "\n",
    "# Plotting functions\n",
    "\n",
    "def plot_input(sample):\n",
    "    sample_np = sample.squeeze().cpu().numpy()\n",
    "    plot_fig_input.data = []  # Clear previous traces\n",
    "    if sample_np.ndim == 2:  # (channels, time)\n",
    "        trace = go.Heatmap(z=sample_np,\n",
    "                           colorscale='Viridis', name='Input',\n",
    "                           colorbar=dict(title='Amplitude'))\n",
    "        plot_fig_input.add_trace(trace)\n",
    "        plot_fig_input.update_layout(\n",
    "            title=f'Input Signal #{sample_id}',\n",
    "            xaxis_title='Time', yaxis_title='Channel Index',\n",
    "            # Set figure size to match plot\n",
    "            width=5 * sample_np.shape[1], height=2.5 * sample_np.shape[0]\n",
    "        )\n",
    "    else:\n",
    "        plot_fig_input.update_layout(title='Input (Unsupported shape)')\n",
    "    plot_fig_input.show()\n",
    "\n",
    "\n",
    "def plot_activation(layer_name):\n",
    "    act = activations[layer_name]\n",
    "    act_np = act.squeeze().cpu().numpy()\n",
    "    plot_fig.data = []  # Clear previous traces\n",
    "    if act_np.ndim == 2:  # (channels, time)\n",
    "        plot_height = max(300, 2.5 * act_np.shape[0])\n",
    "        plot_width = min(800, max(500, 5 * act_np.shape[1]))\n",
    "\n",
    "        trace = go.Heatmap(z=act_np,\n",
    "                           colorscale='Viridis', name=f'Convolutional Layer',\n",
    "                           colorbar=dict(title='Activation'))\n",
    "\n",
    "        plot_fig.add_trace(trace)\n",
    "        plot_fig.update_layout(\n",
    "            title=f'{layer_name} - Convolutional Layer',\n",
    "            yaxis=dict(title='Channel Index', tickmode='linear',\n",
    "                       dtick=min(50, act_np.shape[0] // 10)),\n",
    "            xaxis=dict(title='Time', tickmode='linear',\n",
    "                       dtick=min(20, act_np.shape[1] // 10)),\n",
    "            width=plot_width, height=plot_height\n",
    "        )\n",
    "    elif act_np.ndim == 1:  # (features,)\n",
    "        is_final_layer = act_np.shape[0] == 39\n",
    "\n",
    "        # Pad act_np if not a multiple of activations_per_row\n",
    "        pad_len = (-act_np.size % activations_per_row)\n",
    "        if pad_len != 0:\n",
    "            act_np = np.copy(act_np)  # Ensure we don't modify the original\n",
    "            act_np = np.pad(act_np, (0, pad_len), constant_values=np.nan)\n",
    "        act_np = act_np.reshape(-1, activations_per_row)\n",
    "\n",
    "        plot_height = max(400, 25 * act_np.shape[0])\n",
    "        plot_width = 25 * activations_per_row\n",
    "\n",
    "        trace = go.Heatmap(z=act_np,\n",
    "                           colorscale='Viridis', name='Features')\n",
    "        plot_fig.add_trace(trace)\n",
    "\n",
    "        if is_final_layer:\n",
    "            # fill a square grid indexed by predicted_label\n",
    "            predicted_label = np.nanargmax(act_np)\n",
    "            predicted_label_x = predicted_label % activations_per_row\n",
    "            predicted_label_y = predicted_label // activations_per_row\n",
    "            trace = go.Scatter(\n",
    "                x=[predicted_label_x - 0.5, predicted_label_x + 0.5, predicted_label_x +\n",
    "                    0.5, predicted_label_x - 0.5, predicted_label_x - 0.5],\n",
    "                y=[predicted_label_y - 0.5, predicted_label_y - 0.5, predicted_label_y +\n",
    "                    0.5, predicted_label_y + 0.5, predicted_label_y - 0.5],\n",
    "                mode='lines',\n",
    "                line=dict(color='red', width=0),\n",
    "                fill='toself',\n",
    "                fillpattern=dict(\n",
    "                    shape='x',\n",
    "                    solidity=0.4,\n",
    "                    size=6,\n",
    "                    fgcolor='red',\n",
    "                    bgcolor='rgba(0,0,0,0.1)'  # Semi-transparent background\n",
    "                ),\n",
    "                name='Predicted Label Index',\n",
    "                zorder=10\n",
    "            )\n",
    "            plot_fig.add_trace(trace)\n",
    "\n",
    "        plot_fig.update_layout(\n",
    "            title=f'{layer_name} - Dense' +\n",
    "            f' (Final, {predicted_label}?)' if is_final_layer else '',\n",
    "            xaxis=dict(title='Feature Index', tickmode='linear', dtick=4),\n",
    "            yaxis=dict(title='', tickmode=\"array\",\n",
    "                       tickvals=np.arange(0, act_np.shape[0], 4),\n",
    "                       ticktext=np.arange(0, act_np.shape[0], 4) * activations_per_row),\n",
    "            xaxis_tickangle=0,\n",
    "            width=plot_width, height=plot_height)\n",
    "    else:\n",
    "        plot_fig.update_layout(title=f'{layer_name} (Unsupported shape)')\n",
    "    plot_fig.show()\n",
    "\n",
    "\n",
    "layer_selector = widgets.ToggleButtons(\n",
    "    options=list(activations.keys()),\n",
    "    value=list(activations.keys())[-1],\n",
    "    description='Layer:'\n",
    ")\n",
    "\n",
    "\n",
    "def on_change(change):\n",
    "    plot_activation(layer_selector.value)\n",
    "\n",
    "\n",
    "layer_selector.observe(on_change, names='value')\n",
    "\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([layer_selector, ]),\n",
    "    widgets.HBox([plot_fig_input, plot_fig])\n",
    "]))\n",
    "plot_input(sample)\n",
    "plot_activation(layer_selector.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libribrain-phoneme (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
